---
typora-root-url: 实验文档\图片
---

# 一、数据集信息

## arxiv原始数据集

|                   | 样本总数 | 平均章节数 | 平均句子数 | 平均全文长度 | 平均句子长度 |
| ----------------- | -------- | ---------- | ---------- | ------------ | ------------ |
| 训练集(train)正文 | 203037   | 5.54       | 206.38     | 6218.02      | 30.13        |
| 摘要              |          |            | 9.87       | 307.79       | 31.20        |
|                   |          |            |            |              |              |
| 验证集(val)       | 6436     | 5.66       | 204.24     | 6060.80      | 29.68        |
| 摘要              |          |            | 5.60       | 175.77       | 31.40        |
|                   |          |            |            |              |              |
| 测试集(test)      | 6440     | 5.68       | 205.68     | 6067.50      | 29.50        |
| 摘要              |          |            | 5.69       | 177.42       | 31.17        |

### 1. 对章节数的分析：

* 验证集(val)

```python
Counter({5: 1632, 6: 1308, 4: 1257, 7: 732, 8: 443, 3: 404, 9: 249, 10: 128, 2: 116, 11: 68, 1: 29, 12: 26, 13: 22, 14: 9, 16: 4, 15: 4, 24: 1, 22: 1, 17: 1, 19: 1, 21: 1})
```

* 测试集(test)

```python
Counter({5: 1602, 6: 1268, 4: 1256, 7: 778, 8: 450, 3: 443, 9: 225, 10: 127, 2: 102, 11: 63, 12: 42, 13: 28, 1: 27, 14: 11, 16: 5, 15: 5, 17: 3, 18: 1, 21: 1, 26: 1, 19: 1, 25: 1})
```

* 训练集(train)

```python
Counter({5: 48220, 4: 38890, 6: 37703, 7: 23685, 3: 14916, 8: 13557, 9: 7520, 1: 4974, 2: 4679, 10: 4018, 11: 2161, 12: 1099, 13: 668, 14: 352, 15: 212, 16: 131, 17: 91, 18: 49, 19: 29, 20: 26, 21: 16, 22: 12, 23: 6, 24: 4, 26: 4, 32: 2, 30: 2, 31: 2, 25: 1, 38: 1, 27: 1, 36: 1, 29: 1, 60: 1, 28: 1, 42: 1, 33: 1})
```

**key:章节数， value:频数（按照频数排序）**

可以看到，文章中大部分都是（4，5，6）个章节。

小部分只有（1，2）章节，对于这部分，我们选择完全保留。

而（3）章节比较特殊，可能需要全保留，可能需要删除。所以我对有三个章节的文章再进行一次统计，对他们的内容进行分析，再过滤。



### 2. 对章节内容的分析：

* 开头

**introduction、motivation、background、overview、observations、highlights**、（各个文章中自定义的章节名称）......

* 结尾以及倒数第二章

**conclusions、summary、discussion、results、outlook、analysis、methods**、acknowledgement、appendix、references、future work、......

![章节名分析test](/章节名分析test.png)

![](/章节名分析val.png)



![](/章节统计train.png)

![章节统计val](/章节统计val.png)

![](/章节统计test.png)



将章节名信息进行统计，发现开头大多是以introduction或其变体构成，还有其他出现频数较高的有motivation、background、overview、observations、highlights等。有些出现频数为1的章节名，这些都为作者自定义的章节名。考虑到第一节这个特殊的位置，我将这部分都留下。 

对于总结部分，发现其可能出现于文章最后一段或最倒数第二段，还可能没有。统计了文章结尾以及倒数第二段出现过的章节名信息，选出一些高频名放入集合，筛选文章时倒叙遍历，如果出现在集合中则留下，没有则删除。



## tiny-arxiv数据集（不符合的直接删去）

|        | 样本总数 | 平均段落数 | 文章平均句子数 | 文章平均长度 | 平均句子长度 |
| ------ | -------- | ---------- | -------------- | ------------ | ------------ |
| 训练集 | 166784   | 2.37       | 68.42          | 1857.29      | 29.33        |
| 验证集 | 5538     | 2.21       | 65.85          | 1883.06      | 28.31        |
| 测试集 | 5598     | 2.32       | 64.76          | 1817.69      | 28.50        |

## tiny-arxiv数据集（不符合的也保留第一章和最后一章）

|        | 样本总数 | 平均段落数 | 文章平均句子数 | 文章平均长度 | 平均句子长度 |
| ------ | -------- | ---------- | -------------- | ------------ | ------------ |
| 训练集 | 203037   | 2.63       | 75.17          | 2103.97      | 28.73        |
| 验证集 | 6436     | 2.75       | 73.22          | 2011.35      | 28.66        |
| 测试集 | 6440     | 2.71       | 73.45          | 2020.46      | 29.01        |

# 二、模型

## 可用模型

​																																				   **原始数据集**														**删减过的数据集**

| 模型                            | Rouge-1 | Rouge-L | Rouge-1 | Rouge-L |
| ------------------------------- | ------- | ------- | ------- | ------- |
| Poniter-Network-Gen             | 32.06   | 25.16   |         |         |
| discourse-aware model(原文模型) | 35.80   | 31.80   | 29.03   | 22.37   |
| Bert                            |         |         |         |         |
| BertSum()                       |         |         |         |         |
| Sentence-Bert                   | 20.21   | 14.18   | 25.79   | 17.22   |
| Longformer                      |         |         |         |         |
| Pegasus                         |         |         |         |         |

## 有待商榷

| 模型                                  | 备注                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| RoBert                                |                                                              |
| BertSum(BertSum-ext，BertSum-ext-abs) | 我在短文本CNN/DM上跑过这个模型，最多只能处理一个Bert的长度，超过512的都删去，对长文本模型并不适用。 |
| MatchSum                              | 同样我在短文本CNN/DM上跑过这个模型，效果很好，也是很长一段时间都在榜首的模型。但是这个模型也是只针对 |
| Big-Bird                              | 文章中给的效果很好，但是目前未开源。                         |
| 图神经网络                            | 考虑中                                                       |



# 三、实验计划

计划一：提出这个数据集的文章中的模型(discourse-aware model)在tiny-arxiv上跑

计划二：利用sentence-bert做一个无监督抽取摘要

计划三：构建一个抽取式摘要的标签对（原数据集模式只是，正文-摘要，如果要跑抽取式摘要需要手动来构建一个正文-抽取摘要的标签，来评判抽取摘要的好坏）

计划四：利用Lonformer做一个抽取式摘要

计划五：利用Pegasus做一个纯生成式的摘要

# 四、实验记录

1. discourse-aware model为tensorflow1版本，比较混乱，跑这个的时候配置环境等出错。在github上找到了一个非官方的pytorch版本的实现。我对输入输出进行了改动，修改了部分源码，可以跑成功实验。





# 五、分析

一、同样的模型在原arxiv数据集上和tiny-arxiv数据集上跑，后者效果下降。比较出乎意料，

可能的问题：

1. 数据集质量问题，数据集改造的不够仔细，可能删多了
2. pytorch和tensorflow，我用的非官方的pytorch的代码跑的tiny-arxiv
3. 实验设置问题，并没有跑很多次然后取最优结果来比较





